# -*- coding: utf-8 -*-
"""Project_Python6382.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fzr__mjI4KTLUVdjbBhaIHkKuUYmLL_R
"""

class Lodging:
    def __init__(self, date, name, category, type, rating, price, average_revenue):
        self.date = date
        self.name = name
        self.category = category
        self.type = type
        self.rating = rating
        self.price = price
        self.average_revenue = average_revenue
        self.unique_id = id(self)

    def __str__(self):
        return f"{self.unique_id}, {self.date}, {self.name}, {self.category},{self.type}, {self.rating}, {self.price}, {self.average_revenue}"

# date,name,category,rating,price,average_revenue
class Travel(Lodging):
    def __init__(self, date, name, category, rating, price, average_revenue):
        super().__init__(date, name, category, "Travel", rating, price, average_revenue)

class Vacation(Lodging):
    def __init__(self, date, name, category, rating, price, average_revenue):
        super().__init__(date, name, category, "Vacation", rating, price, average_revenue)

# date,name,rating,price,average_revenue
class HotelRoom(Travel):
    def __init__(self, date, name, rating, price, average_revenue):
        super().__init__(date, name, "HotelRoom", rating, price, average_revenue)

class Cottage(Vacation):
    def __init__(self, date, name, rating, price, average_revenue):
        super().__init__(date, name, "Cottage", rating, price, average_revenue)

class BeachHouse(Vacation):
    def __init__(self, date, name, rating, price, average_revenue):
        super().__init__(date, name, "BeachHouse", rating, price, average_revenue)

str(Lodging)

# Testing the code
VacationLodging = Vacation("2022-10-08","Urban Retreat", "Cottage", 1.0, 85.32, 69020.0)
print(str(VacationLodging))

# Loading the pickle file
import pickle

# Open the pickle file and load the data
with open('Lodgingpkl638250202.dat', 'rb') as f:
    data = pickle.load(f)

import csv

# Open the CSV file in write mode
with open('dataset1.csv', 'w', newline='') as f:
    writer = csv.writer(f)

    # Write the header
    writer.writerow(["unique_id", "date", "name", "category", "type", "rating", "price", "average_revenue"])

    # Write the data
    for obj in data:
        writer.writerow(str(obj).split(','))

x = 45
y = 67
print(id(x))
print(id(y))
print(type(x))

rrr = 'Hi how are you'
print(rrr.split(' '))

with open('dataset1.csv', 'r') as R:
  print(R.read())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
df = pd.read_csv('dataset.csv')

df.head(5)

df.tail(5)

df.info()

df.dtypes

df.isna().sum()

df['average_revenue'] = df['average_revenue'].replace(' ', np.nan)
df['average_revenue'] = df['average_revenue'].astype(float)

df.info()

df['price'] = df['price'].replace(' ', np.nan)
df['price'] = df['price'].astype(float)

df.info()

from datetime import datetime
df['date'] = df['date'].replace(' ', np.nan)
df['date'] = pd.to_datetime(df['date'], dayfirst=False)

df.info()

df.isna().sum()

for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = df[col].replace(' ', np.nan)

df.info()

df = df.rename(columns = {'unique_id': 'uid'})
df

dfd = df.copy()
dfd.head(10)

dfd.isna().sum()
dfd.info()
dfd.to_csv('D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/cleaned_csv_file.csv')

dfd.set_index('uid', inplace=True)
dfd

dfd.info()

dfd.isna().sum()

dfd.shape

# Calculate percentage of missing values in each column
missing_percentages = df.isnull().mean() * 100
print("Percentage of missing values in each column:")
print(missing_percentages)

# As the percentage of missing value on average per column is less than 4.2%, we descide to remove the rows containing nan values
# We remove all the rows of the dataframe that contains nan values in the date column
dfd = dfd.dropna(subset=['date'])
dfd.isna().sum()

print(f'shape of the cleaned dataframe is:  {dfd.shape}')

dfd.isnull().sum()

dfd['rating'] = dfd.groupby(['type', 'category', 'name'])['rating'].transform(lambda x: x.fillna(x.mode()[0]))

dfd.head(10)

print(dfd.isnull().sum())
print(dfd.shape)

#dfd['rating'] = dfd.groupby(['type', 'category', 'name'])['price'].transform(lambda x: x.fillna(x.median()[0]))
#dfd['price'] = df.groupby(['type', 'category', 'name'])['price'].transform(lambda x: x.fillna(x.median()))
#dfd['average_revenue'] = df.groupby(['type', 'category', 'name'])['average_revenue'].transform(lambda x: x.fillna(x.median()))
dfd['price'] = dfd.groupby(['type', 'category', 'name'])['price'].transform(lambda x: x.fillna(x.median()))
dfd['average_revenue'] = dfd.groupby(['type', 'category', 'name'])['average_revenue'].transform(lambda x: x.fillna(x.median()))

print(dfd.isnull().sum())
print(dfd.shape)

dfd.head(20)

dfd.tail(400)

# Extract year, month, and day into separate columns
dfd['year'] = dfd['date'].dt.year
dfd['month'] = dfd['date'].dt.month
dfd['day'] = dfd['date'].dt.day
dfd.head(10)

#Map numeric month values to month names
month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',
               7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}
dfd['month'] = dfd['month'].map(month_names)
dfd.head(10)

# dropping the date column
#dfd = dfd.drop(columns=['date'], inplace=True)
dfd = dfd.drop('date', axis=1)

print(dfd.head(10))
print(dfd.shape)

dfd.head(10)

for col in dfd.columns:
    if col == 'uid':
        continue
    print(f'{dfd[col].value_counts()}')
    print('\n')

dfd['year'].unique()

dfd['year'].value_counts()

dfd.head(10)

dfd['category'].value_counts()

print(dfd.dtypes)
#dfd['rating']= dfd['rating'].astype('int64')

dfd['rating'] = dfd['rating'].astype('int64')
dfd.info()

# We will bin the rating column into different ranges and then plot a bar graph based on binned categories
# Define the bins ranges and labels
bins = [0, 2 , 4, 5]
labels = ['Low', 'Medium', 'High']

# Bin the rating column
dfd['rating_category'] = pd.cut(dfd['rating'], bins = bins, labels=labels, include_lowest=True)

# Grouped by the rating_category and category, and count occurrences
grouped_data = dfd.groupby(['rating_category', 'category']).size().unstack(fill_value=0)

# Plotting the stacked bar graph directly from the unstacked DataFrame
#plt.figure(figsize=(16,9))
grouped_data.plot(kind='bar', stacked=True)
plt.xlabel('Rating Category')
plt.ylabel('Count')
plt.title('Count of Ratings in Different Categories')
plt.legend(title='Category')
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/BAR_STACKED.PDF")
plt.show()

"""# Box Plot"""

(dfd['price']).mean()
#min(dfd['price'])
#max(dfd['average_revenue'])
#min(dfd['average_revenue'])

80 - 9.475*3

'''
Use the boxplot() function to plot boxplots.
'''
import matplotlib.pyplot as plt
#value1 = dfd['rating']
value2 = dfd['price']
value3 = dfd['average_revenue']
plt.figure(figsize=(12, 6))  # Enlarge the figure
plt.subplot(1,2,1)
flierprops = dict(marker='o', markerfacecolor='r', markersize=5, linestyle='--', markeredgecolor='b')
plt.boxplot(value2, whis= 1.5, notch = True, flierprops = flierprops)
plt.yticks(range(4, 200, 10))
plt.ylabel('Price')
plt.title('A Boxplot')
#plt.grid(False)
#plt.title('A Boxplot')
plt.subplot(1,2,2)
flierprops = dict(marker='o', markerfacecolor='r', markersize=5, linestyle='--', markeredgecolor='b')
plt.boxplot(value3, whis= 1.5, notch = True, flierprops = flierprops)
plt.yticks(range(8000, 150000, 8000))
plt.ylabel('Average Revenue')
plt.title('A Boxplot')
plt.subplots_adjust(wspace=1.0)  # Adjust horizontal space between subplots
plt.grid(True)
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/BOX_PLOT.PDF")
plt.show()

import numpy as np
import seaborn as sns
from scipy.stats import skewnorm
import matplotlib.pyplot as plt
#plt.figure(figsize=(12, 6))  # Enlarge the figure
a = 0.5 #value for skewness
# The value of skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean.
r = dfd['price']
mean1= np.mean(r)
median1 = np.median(r)
sns.displot(r, height=6, aspect=2)
plt.axvline(x=median1, color = 'blue')
plt.axvline(x=mean1, color = "red", linestyle='--')
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/DISTRIBUTION_PLOT.PDF")

import numpy as np
import seaborn as sns
from scipy.stats import skewnorm
import matplotlib.pyplot as plt
#plt.figure(figsize=(12, 6))  # Enlarge the figure
a = 0.5 #value for skewness
# The value of skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean.
r = dfd['average_revenue']
mean1= np.mean(r)
median1 = np.median(r)
sns.displot(r, height=6, aspect=2)
plt.axvline(x=median1, color = 'blue')
plt.axvline(x=mean1, color = "red", linestyle='--')
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/DISTRIBUTION_PLOT.PDF")

dfd['average_revenue'].mean()

"""# LINE PLOT
### Line plots are typically used for time series data to show the trend of a variable over time. In your dataset, the following features can be plotted against ‘year’, ‘month’, or ‘day’ using a line plot:
"""

dfd_2022 = dfd[dfd['year'] == 2022]
dfd_2023 = dfd[dfd['year'] == 2023]
dfd_2022_average_revenue =dfd_2022.groupby('month')['average_revenue'].mean()
dfd_2023_average_revenue =dfd_2023.groupby('month')['average_revenue'].mean()
print(dfd_2023_average_revenue)
months_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
x = dfd_2022_average_revenue.index.astype(pd.CategoricalDtype(categories=months_order, ordered=True))
y1= dfd_2022_average_revenue.values
y2= dfd_2023_average_revenue.values
#print(y1)
#print(y2)
plt.figure(figsize=(12, 6))
plt.plot(x, y1)
plt.xlabel('Month')
plt.ylabel('Average Revenue')
plt.title('Average Revenue per Month in the Year 2022"')
plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility
plt.legend()
plt.tight_layout()  # Adjust spacing to prevent overlapping elements
plt.grid(True)
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/LINE_PLOT.PDF")
plt.show()

# Assuming 'dfd' is your DataFrame with columns 'month', 'year', and 'average_revenue'

# Define the order of months for the x-axis
months_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']

# Reorder the DataFrame to ensure the correct order of months
dfd['month'] = pd.Categorical(dfd['month'], categories=months_order, ordered=True)

# Filter the DataFrame for the years 2022 and 2023
dfd_2022 = dfd[dfd['year'] == 2022]
dfd_2023 = dfd[dfd['year'] == 2023]

# Calculate the average revenue for each month in 2022 and 2023
dfd_2022_average_revenue = dfd_2022.groupby('month')['average_revenue'].median()
dfd_2023_average_revenue = dfd_2023.groupby('month')['average_revenue'].median()

# Extract x-axis (month) and y-axis (average revenue) values
x = dfd_2022_average_revenue.index
y1 = dfd_2022_average_revenue.values
y2 = dfd_2023_average_revenue.values

# Plotting the line plot for average revenue per month in 2022 and 2023
plt.figure(figsize=(12, 6))
plt.plot(x, y1, label='2022')  # Legend label for 2022 data
plt.plot(x, y2, label='2023')  # Legend label for 2023 data
plt.xlabel('Month')
plt.ylabel('Average Revenue')
plt.title('Average Revenue per Month in the Years 2022 and 2023')

arrow_properties = {
'facecolor': 'green',
'facecolor': 'green',
'headlength': 5,
'width': 4
}

arrow_properties1 = {
'facecolor': 'red',
'facecolor': 'red',
'headlength': 5,
'width': 4
}

plt.annotate('Dip in Average Revenue', xy=('September', 91620), xytext=('November', 91300), arrowprops=arrow_properties)
plt.annotate('Peak in Average Revenue', xy=('August', 92200), xytext=('November', 93300), arrowprops=arrow_properties1)

plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility
plt.legend()  # Show legend with labels
plt.tight_layout()  # Adjust spacing to prevent overlapping elements
plt.grid(True)  # Show gridlines
plt.ylim(ymin=90000)  # Adjust ymin as needed
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/LINE_PLOT.PDF")
plt.show()

dfd[dfd['year']==2023]

"""# SCATTER PLOT
### Scatter plots are typically used to observe relationships between two numerical variables. In your dataset, the following pairs of features can be
"""

# x-axis values
x = dfd['month']
# y-axis values
y = dfd['average_revenue']
plt.figure(figsize=(12, 6))
# plotting points as a scatter plot
plt.scatter(x, y, color= 'red', marker= "d")
# x-axis label
plt.xlabel('Rating Category')
# frequency label
plt.ylabel('Price (in \$\$)')
# Rotate x-axis labels for better visibility
plt.xticks(rotation=45)
# plot title
plt.title('Rating category vs Price')
plt.grid(True) # Note the use of the grid() function to display a grid
# function to show the plot
plt.tight_layout()
plt.show()

# Assuming 'dfd' is your DataFrame with columns 'month', 'year', 'category', 'price', and 'average_revenue'

# Filter the DataFrame for the year 2022
dfd_2022 = dfd[dfd['year'] == 2022]

# Get unique categories
categories = dfd_2022['category'].unique()

# Create subplots for each category
#plt.figure(figsize=(12, 6))
fig, axs = plt.subplots(nrows=len(categories), ncols=1, figsize=(8, 4 * len(categories)))

# Iterate through each category and plot the scatter plot
for i, category in enumerate(categories):
    category_data = dfd_2022[dfd_2022['category'] == category]
    ax = axs[i]  # Select the appropriate subplot
    ax.scatter(category_data['month'], category_data['average_revenue'], color='red', marker='d')
    ax.set_xlabel('Month')
    ax.set_ylabel('Average Revenue')
    ax.set_title(f'Average revenue variability for Category: {category}')
    # Rotate x-axis labels for better visibility
    ax.tick_params(axis='x', rotation=45)  # Adjust rotation angle as needed
    ax.grid(True)
    plt.tight_layout()

# Adjust layout and spacing
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/SCATTER_PLOT.PDF")
plt.show()

"""# HISTOGRAMS
### Histograms are used to visualize the distribution of a single numerical variable.
"""

# Filter the DataFrame for the year 2022
dfd_2022 = dfd[dfd['year'] == 2022]

# Get unique categories
categories = dfd_2022['category'].unique()

# Create a single subplot for each category
fig, axs = plt.subplots(nrows=len(categories), ncols=1, figsize=(8, 4 * len(categories)))

# Iterate through each category and plot the histogram in the corresponding subplot
for i, category in enumerate(categories):
    category_data = dfd_2022[dfd_2022['category'] == category]
    axs[i].hist(category_data['price'], bins=5, color='blue', alpha=0.7)  # Adjust bins and alpha as needed
    axs[i].set_xlabel('Price')
    axs[i].set_ylabel('Frequency')
    axs[i].set_title(f'Histogram of Prices for Type: {category}')
    axs[i].grid(True)
    #axs[i].tight_layout()  # Use axs[i].tight_layout() instead of plt.tight_layout()
    # axs[i].set_xlim(0, 160)  # Uncomment and adjust xlim if needed
    # axs[i].set_ylim(0, 4500)  # Uncomment and adjust ylim if needed

# Save and show the plot
plt.tight_layout()
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/HIST_PLOT.PDF")
plt.show()

"""# PIE CHART
### Pie charts are used to visualize the distribution of a single categorical variable
"""

# Calculate the frequency of each category
name_counts = dfd['name'].value_counts()
name_counts

# Plotting the pie chart
# Define colors for the pie chart slices (using nine distinct colors)
colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0', '#ffb3e6', '#ff6666', '#c2f0c2', '#c2f0f0']

# Plotting the pie chart
plt.figure(figsize=(7, 5))
plt.pie(name_counts, labels=name_counts.index, autopct='%2.2f%%', colors=colors, explode=(0,0.1,0,0.6,0.5,0.4,0.1,0.2,0.3), startangle=270, radius=2)
#plt.axis('equal')
plt.title('Category Frequencies')
plt.savefig("D:/Work/Gre/UTD/Courses/Spring_II/MIS6382/Project/PIE_PLOT.PDF")
plt.legend(loc='best', bbox_to_anchor=(2.1, 1))
plt.show()

dfd['name'].nunique()

"""# HEATMAPS
##### The heatmap in this example helps to visualize and analyze the relationships between categorical variables ('name' and 'category') based on the average prices of items in each category. It allows for easy comparison and identification of patterns or trends in pricing across different categories and items.
"""

dfd.head(10)

#heatmap_data = pd.DataFrame(data)

# Pivot the data to create a heatmap
heatmap_data = dfd.pivot_table(index='name', columns='category', values='price', aggfunc='mean')

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(heatmap_data, cmap='viridis', annot=True, fmt=".1f", linewidths=0.5)
plt.title('Average Price by Name and Category')
plt.xlabel('Category')
plt.ylabel('Name')
plt.show()

#heatmap_data = pd.DataFrame(data)

# Pivot the data to create a heatmap
heatmap2_data = dfd.pivot_table(index='name', columns='category', values='average_revenue', aggfunc='mean')

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(heatmap2_data, cmap='coolwarm', annot=True, fmt=".1f", linewidths=0.5)
plt.title('Average Revenue by Name and Category')
plt.xlabel('Category')
plt.ylabel('Name')
plt.show()

"""## As we can see from the Heat map the price, and the average revenue of HotelRoom has more variance than compared to other categories like BeachHouse and Cottage.

# Conclusion

## 1. The average revenue goes at its highest in August and at the same time attains its lowest value in September in the year 2022
## 2. the count of prices for booking Categories of the likes BeachHouse and Hotelroom tend to follow a Guassian (Normal) Distribution and Cottage industry is slightly leftskewed
## 2. Similarly if we the distribution of count of prices for the whole price for all category, we see that is Normally distributed with a mean close to 79.6 and in a normal distribution Mean = Median. But if we see the distribution of counts in average_revenue for all categories, it tends to have a right skewed distribution. In a right skewed distribution the concentration of the data points lie more in the right region than in the left region and median > mean in that case

## The most transactional industry is represented by the Beach category industries and it accounts for total (Seaside + Sunset Retreat + Ocean Front Villa) = (60.9 + 16.23 + 0.63 )% = 77.76% of the total industries
## Family farm house of Cottage industry is trying to make compete with the beachHouse industry as we can see it is slow making an impact, with this trend it may exceed the former.
"""